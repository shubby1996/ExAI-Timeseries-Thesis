{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9daa008a",
   "metadata": {},
   "source": [
    "# HPO Two-Stage System - Job Submission & Monitoring\n",
    "\n",
    "This notebook integrates the newly created **two-stage HPO system** with SLURM job management.\n",
    "\n",
    "## Overview\n",
    "- **Stage 1**: Optimize model architecture for MAE (50 trials, ~4-10 hours)\n",
    "- **Stage 2**: Calibrate quantile levels for PICP ≈ 80% (20 trials, ~2-3 hours)\n",
    "- **Resources**: A100 GPU, 10-hour time limit, 32GB RAM\n",
    "- **Models**: NHITS_Q and TIMESNET_Q on heat and water datasets\n",
    "\n",
    "## Workflow\n",
    "1. Submit all Stage 1 experiments (priority order)\n",
    "2. Monitor progress\n",
    "3. Submit Stage 2 as Stage 1 completes\n",
    "4. View and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7df625",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup\n",
    "\n",
    "Import required libraries and verify the HPO infrastructure is in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "971e7402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "✓ Current directory: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "✓ Python version: 3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:57:12) \n",
      "[GCC 13.3.0]\n",
      "✓ Imports ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Detect project root by searching upwards or for known repo folder name\n",
    "def find_repo_root(start_dir):\n",
    "    path = os.path.abspath(start_dir)\n",
    "    # Upward search for markers\n",
    "    for _ in range(6):\n",
    "        if os.path.exists(os.path.join(path, 'hpo')) and os.path.exists(os.path.join(path, 'README.md')):\n",
    "            return path\n",
    "        parent = os.path.abspath(os.path.join(path, '..'))\n",
    "        if parent == path:\n",
    "            break\n",
    "        path = parent\n",
    "    # Fallback: look for known repo folder in current directory\n",
    "    try:\n",
    "        for name in os.listdir(start_dir):\n",
    "            candidate = os.path.join(start_dir, name)\n",
    "            if name == 'ExAI-Timeseries-Thesis' and os.path.isdir(candidate):\n",
    "                return candidate\n",
    "    except Exception:\n",
    "        pass\n",
    "    return os.path.abspath(start_dir)\n",
    "\n",
    "project_root = find_repo_root(os.getcwd())\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Change to project root for all operations\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f'✓ Project root: {project_root}')\n",
    "print(f'✓ Current directory: {os.getcwd()}')\n",
    "print(f'✓ Python version: {sys.version}')\n",
    "print(f'✓ Imports ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a46ca",
   "metadata": {},
   "source": [
    "## 2. HPO Configuration - A100 GPU with 10 Hours\n",
    "\n",
    "Define SLURM and HPO settings for submitting jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9caedec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SLURM Config: {'partition': 'a100', 'gres': 'gpu:a100:1', 'time': '10:00:00', 'cpus_per_task': 8, 'job_name_prefix': 'hpo'}\n",
      "✓ HPO Config - Stage1 trials: 50\n",
      "✓ HPO Config - Stage2 trials: 20\n",
      "✓ Priority order: [('water', 'TIMESNET_Q'), ('heat', 'NHITS_Q'), ('water', 'NHITS_Q'), ('heat', 'TIMESNET_Q')]\n",
      "✓ Using scripts:\n",
      "  - submit: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/submit_experiment.py\n",
      "  - status: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/check_status.py\n",
      "✓ Job map: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/hpo_current_jobs.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HPO RUNNER CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# SLURM Resource Configuration (informational)\n",
    "SLURM_CONFIG = {\n",
    "    'partition': 'a100',              # Valid GPU partition\n",
    "    'gres': 'gpu:a100:1',             # A100 GPU (1 GPU)\n",
    "    'time': '10:00:00',               # 10 hours\n",
    "    'cpus_per_task': 8,               # 8 CPU cores\n",
    "    'job_name_prefix': 'hpo',         # Job name prefix\n",
    "}\n",
    "\n",
    "# HPO Experiment Configuration\n",
    "HPO_CONFIG = {\n",
    "    'stage1_trials': 50,              # Stage 1: 50 trials\n",
    "    'stage2_trials': 20,              # Stage 2: 20 trials\n",
    "    'priority_order': [\n",
    "        ('water', 'TIMESNET_Q'),      # Best overall performer\n",
    "        ('heat', 'NHITS_Q'),          # Best heat, worst PICP\n",
    "        ('water', 'NHITS_Q'),         # Fast training\n",
    "        ('heat', 'TIMESNET_Q'),       # Architecture comparison\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Paths (absolute)\n",
    "TRACKING_FILE = os.path.join(project_root, 'hpo/tracking/experiments.csv')\n",
    "JOB_MAP_FILE = os.path.join(project_root, 'hpo/hpo_current_jobs.json')\n",
    "\n",
    "# Scripts (absolute)\n",
    "SUBMIT_SCRIPT = os.path.join(project_root, 'hpo/submit_experiment.py')\n",
    "CHECK_STATUS_SCRIPT = os.path.join(project_root, 'hpo/check_status.py')\n",
    "\n",
    "print('✓ SLURM Config:', SLURM_CONFIG)\n",
    "print('✓ HPO Config - Stage1 trials:', HPO_CONFIG['stage1_trials'])\n",
    "print('✓ HPO Config - Stage2 trials:', HPO_CONFIG['stage2_trials'])\n",
    "print('✓ Priority order:', HPO_CONFIG['priority_order'])\n",
    "print('✓ Using scripts:')\n",
    "print('  - submit:', SUBMIT_SCRIPT)\n",
    "print('  - status:', CHECK_STATUS_SCRIPT)\n",
    "print('✓ Job map:', JOB_MAP_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91a776",
   "metadata": {},
   "source": [
    "## 3. Utility Functions\n",
    "\n",
    "Helper functions to submit jobs, check status, and manage the HPO workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d4e3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Utility functions defined: submit_stage_job(), check_experiment_status()\n"
     ]
    }
   ],
   "source": [
    "def submit_stage_job(stage, model, dataset, trials, verbose=True):\n",
    "    \"\"\"\n",
    "    Submit a single HPO stage job using submit_experiment.py\n",
    "    \n",
    "    Args:\n",
    "        stage: 1 or 2\n",
    "        model: 'NHITS_Q' or 'TIMESNET_Q'\n",
    "        dataset: 'heat' or 'water'\n",
    "        trials: number of trials\n",
    "        verbose: print output\n",
    "    \n",
    "    Returns:\n",
    "        job_id or None if submission failed\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        'python', SUBMIT_SCRIPT,\n",
    "        '--stage', str(stage),\n",
    "        '--model', model,\n",
    "        '--dataset', dataset,\n",
    "        '--trials', str(trials)\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Submitting Stage {stage}: {dataset.upper()} + {model}')\n",
    "        print(f'  Script: {SUBMIT_SCRIPT}')\n",
    "        print(f'  CWD: {project_root}')\n",
    "        print(f'  Command: {\" \".join(cmd)}')\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, cwd=project_root)\n",
    "        if result.returncode == 0:\n",
    "            # Parse job_id from output\n",
    "            output_lines = result.stdout.strip().split('\\n')\n",
    "            for line in output_lines:\n",
    "                # Look for \"Job ID: <number>\" pattern\n",
    "                if 'Job ID:' in line:\n",
    "                    parts = line.split(':')\n",
    "                    if len(parts) >= 2:\n",
    "                        job_id = parts[-1].strip()\n",
    "                        if job_id and job_id.isdigit():\n",
    "                            if verbose:\n",
    "                                print(f'  ✓ Submitted as Job {job_id}')\n",
    "                            return job_id\n",
    "            # Fallback: show stdout and return success token\n",
    "            if verbose and result.stdout:\n",
    "                print(result.stdout)\n",
    "            print(f'  ✓ Submission successful (no Job ID parsed)')\n",
    "            return 'submitted'\n",
    "        else:\n",
    "            if verbose and result.stdout:\n",
    "                print(result.stdout)\n",
    "            print(f'  ✗ Submission failed:')\n",
    "            print(f'    stderr: {result.stderr}')\n",
    "            return None\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f'  ✗ Submission timed out')\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f'  ✗ Error: {e}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_experiment_status(model=None, dataset=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Check status of all or filtered experiments using check_status.py\n",
    "    \n",
    "    Args:\n",
    "        model: Filter by model ('NHITS_Q', 'TIMESNET_Q', or None for all)\n",
    "        dataset: Filter by dataset ('heat', 'water', or None for all)\n",
    "        verbose: print output\n",
    "    \n",
    "    Returns:\n",
    "        Status output text or None if check failed\n",
    "    \"\"\"\n",
    "    cmd = ['python', CHECK_STATUS_SCRIPT]\n",
    "    \n",
    "    if model:\n",
    "        cmd.extend(['--model', model])\n",
    "    if dataset:\n",
    "        cmd.extend(['--dataset', dataset])\n",
    "    \n",
    "    if verbose:\n",
    "        filter_str = f'{dataset}+{model}' if dataset and model else (dataset or model or 'all')\n",
    "        print(f'Checking status ({filter_str})...')\n",
    "        print(f'  Script: {CHECK_STATUS_SCRIPT}')\n",
    "        print(f'  CWD: {project_root}\\n')\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, cwd=project_root)\n",
    "        if result.returncode == 0:\n",
    "            if verbose:\n",
    "                print(result.stdout)\n",
    "            return result.stdout\n",
    "        else:\n",
    "            print(f'Error checking status:')\n",
    "            print(result.stderr)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "\n",
    "print('✓ Utility functions defined: submit_stage_job(), check_experiment_status()')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdb16f4",
   "metadata": {},
   "source": [
    "## 4. SUBMIT STAGE 1 BY PRIORITY - Select Single Job\n",
    "\n",
    "Submit one Stage 1 experiment by selecting a priority number (1-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "205137ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1 - SELECT PRIORITY TO SUBMIT\n",
      "================================================================================\n",
      "\n",
      "Available priorities:\n",
      "\n",
      "  1. WATER  + TIMESNET_Q\n",
      "  2. HEAT   + NHITS_Q\n",
      "  3. WATER  + NHITS_Q\n",
      "  4. HEAT   + TIMESNET_Q\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Submitting Priority 4: HEAT + TIMESNET_Q\n",
      "================================================================================\n",
      "\n",
      "Submitting Stage 1: HEAT + TIMESNET_Q\n",
      "  Script: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/submit_experiment.py\n",
      "  CWD: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "  Command: python /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/submit_experiment.py --stage 1 --model TIMESNET_Q --dataset heat --trials 50\n",
      "  ✓ Submitted as Job 1475318\n",
      "\n",
      "✓ Job submitted successfully\n",
      "  Priority: 4\n",
      "  Dataset: HEAT\n",
      "  Model: TIMESNET_Q\n",
      "  Job ID: 1475318\n",
      "  Saved to: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/hpo_current_jobs.json\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('STAGE 1 - SELECT PRIORITY TO SUBMIT')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "print('Available priorities:\\n')\n",
    "for i, (dataset, model) in enumerate(HPO_CONFIG['priority_order'], 1):\n",
    "    print(f'  {i}. {dataset.upper():6} + {model}')\n",
    "\n",
    "print()\n",
    "priority = int(input('Enter priority number (1-4): '))\n",
    "\n",
    "if 1 <= priority <= 4:\n",
    "    dataset, model = HPO_CONFIG['priority_order'][priority - 1]\n",
    "    \n",
    "    print(f'\\n' + '='*80)\n",
    "    print(f'Submitting Priority {priority}: {dataset.upper()} + {model}')\n",
    "    print('='*80 + '\\n')\n",
    "    \n",
    "    job_id = submit_stage_job(\n",
    "        stage=1,\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        trials=HPO_CONFIG['stage1_trials'],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    if job_id:\n",
    "        exp_name = f'{dataset}_{model.lower()}'\n",
    "        job_entry = {exp_name: {'job_id': job_id, 'stage': 1, 'status': 'submitted', 'priority': priority}}\n",
    "        \n",
    "        # Save to job map\n",
    "        if os.path.exists(JOB_MAP_FILE):\n",
    "            with open(JOB_MAP_FILE, 'r') as f:\n",
    "                existing = json.load(f)\n",
    "            existing.update(job_entry)\n",
    "        else:\n",
    "            existing = job_entry\n",
    "        \n",
    "        with open(JOB_MAP_FILE, 'w') as f:\n",
    "            json.dump(existing, f, indent=2)\n",
    "        \n",
    "        print(f'\\n✓ Job submitted successfully')\n",
    "        print(f'  Priority: {priority}')\n",
    "        print(f'  Dataset: {dataset.upper()}')\n",
    "        print(f'  Model: {model}')\n",
    "        print(f'  Job ID: {job_id}')\n",
    "        print(f'  Saved to: {JOB_MAP_FILE}')\n",
    "    else:\n",
    "        print('✗ Submission failed')\n",
    "else:\n",
    "    print('Invalid priority number. Please enter 1-4.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea1075",
   "metadata": {},
   "source": [
    "## 4. SUBMIT STAGE 1 - All Models (Priority Order)\n",
    "\n",
    "Submit all Stage 1 architecture optimization experiments.\n",
    "\n",
    "**Timeline**: ~4-10 hours per model on A100 (depends on model and dataset)\n",
    "**Trials**: 50 per model\n",
    "**Output**: best_params.json for each model+dataset combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0152fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUBMITTING STAGE 1 - ARCHITECTURE OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "Priority order:\n",
      "  1. WATER  + TIMESNET_Q\n",
      "  2. HEAT   + NHITS_Q\n",
      "  3. WATER  + NHITS_Q\n",
      "  4. HEAT   + TIMESNET_Q\n",
      "\n",
      "Confirm submission:\n",
      "Submission cancelled.\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('SUBMITTING STAGE 1 - ARCHITECTURE OPTIMIZATION')\n",
    "print('='*80)\n",
    "print(f'\\nPriority order:')\n",
    "for i, (dataset, model) in enumerate(HPO_CONFIG['priority_order'], 1):\n",
    "    print(f'  {i}. {dataset.upper():6} + {model}')\n",
    "\n",
    "print(f'\\nConfirm submission:')\n",
    "response = input('  Submit all Stage 1 jobs? (yes/no): ').strip().lower()\n",
    "\n",
    "if response in ['yes', 'y']:\n",
    "    print('\\n' + '='*80)\n",
    "    stage1_jobs = {}\n",
    "    \n",
    "    for dataset, model in HPO_CONFIG['priority_order']:\n",
    "        job_id = submit_stage_job(\n",
    "            stage=1,\n",
    "            model=model,\n",
    "            dataset=dataset,\n",
    "            trials=HPO_CONFIG['stage1_trials'],\n",
    "            verbose=True\n",
    "        )\n",
    "        if job_id:\n",
    "            exp_name = f'{dataset}_{model.lower()}'\n",
    "            stage1_jobs[exp_name] = {'job_id': job_id, 'stage': 1, 'status': 'submitted'}\n",
    "            print()\n",
    "    \n",
    "    print('='*80)\n",
    "    print(f'✓ Submitted {len(stage1_jobs)} Stage 1 experiments')\n",
    "    print('='*80)\n",
    "    \n",
    "    # Save job map\n",
    "    if stage1_jobs:\n",
    "        if os.path.exists(JOB_MAP_FILE):\n",
    "            with open(JOB_MAP_FILE, 'r') as f:\n",
    "                existing = json.load(f)\n",
    "            existing.update(stage1_jobs)\n",
    "        else:\n",
    "            existing = stage1_jobs\n",
    "        \n",
    "        with open(JOB_MAP_FILE, 'w') as f:\n",
    "            json.dump(existing, f, indent=2)\n",
    "        print(f'Saved job map to {JOB_MAP_FILE}')\n",
    "else:\n",
    "    print('Submission cancelled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8d14e",
   "metadata": {},
   "source": [
    "## 5. CHECK STAGE 1 STATUS\n",
    "\n",
    "Monitor the progress of Stage 1 experiments. Run this cell periodically to check completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd718bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1 STATUS CHECK\n",
      "================================================================================\n",
      "\n",
      "Checking status (all)...\n",
      "  Script: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/check_status.py\n",
      "  CWD: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HPO EXPERIMENT STATUS\n",
      "================================================================================\n",
      "\n",
      "STAGE 1: ARCHITECTURE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475012\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:11:34\n",
      "  MAE: 0.002022\n",
      "\n",
      "? HEAT - NHITS_Q\n",
      "  Job ID: 1475013\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:12:41\n",
      "  MAE: 0.026382\n",
      "\n",
      "? WATER - NHITS_Q\n",
      "  Job ID: 1475014\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:13:08\n",
      "  MAE: 0.072588\n",
      "\n",
      "? HEAT - TIMESNET_Q\n",
      "  Job ID: 1475015\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:13:29\n",
      "  MAE: 0.089717\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475317\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-28 15:32:21\n",
      "  MAE: 0.002022\n",
      "\n",
      "? HEAT - TIMESNET_Q\n",
      "  Job ID: 1475318\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-28 15:32:30\n",
      "  MAE: 0.089717\n",
      "\n",
      "STAGE 2: CALIBRATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475512\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:56:32\n",
      "\n",
      "? HEAT - NHITS_Q\n",
      "  Job ID: 1475513\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:56:57\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "? WATER - NHITS_Q\n",
      "  Job ID: 1475514\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:57:05\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total experiments: 9\n",
      "Completed: 8\n",
      "Running: 0\n",
      "Pending: 0\n",
      "\n",
      "Stage 1 complete: 4/4\n",
      "  ✓ HEAT - NHITS_Q\n",
      "  ✓ HEAT - TIMESNET_Q\n",
      "  ✓ WATER - NHITS_Q\n",
      "  ✓ WATER - TIMESNET_Q\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "\n",
      "Ready for Stage 2:\n",
      "  python hpo/submit_experiment.py --stage 2 --model TIMESNET_Q --dataset heat\n",
      "  python hpo/submit_experiment.py --stage 2 --model TIMESNET_Q --dataset water\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'================================================================================\\nHPO EXPERIMENT STATUS\\n================================================================================\\n\\nSTAGE 1: ARCHITECTURE\\n--------------------------------------------------------------------------------\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475012\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:11:34\\n  MAE: 0.002022\\n\\n? HEAT - NHITS_Q\\n  Job ID: 1475013\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:12:41\\n  MAE: 0.026382\\n\\n? WATER - NHITS_Q\\n  Job ID: 1475014\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:13:08\\n  MAE: 0.072588\\n\\n? HEAT - TIMESNET_Q\\n  Job ID: 1475015\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:13:29\\n  MAE: 0.089717\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475317\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-28 15:32:21\\n  MAE: 0.002022\\n\\n? HEAT - TIMESNET_Q\\n  Job ID: 1475318\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-28 15:32:30\\n  MAE: 0.089717\\n\\nSTAGE 2: CALIBRATION\\n--------------------------------------------------------------------------------\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475512\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:56:32\\n\\n? HEAT - NHITS_Q\\n  Job ID: 1475513\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:56:57\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n? WATER - NHITS_Q\\n  Job ID: 1475514\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:57:05\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n================================================================================\\nSUMMARY\\n================================================================================\\nTotal experiments: 9\\nCompleted: 8\\nRunning: 0\\nPending: 0\\n\\nStage 1 complete: 4/4\\n  ✓ HEAT - NHITS_Q\\n  ✓ HEAT - TIMESNET_Q\\n  ✓ WATER - NHITS_Q\\n  ✓ WATER - TIMESNET_Q\\n\\n================================================================================\\nNEXT STEPS\\n================================================================================\\n\\nReady for Stage 2:\\n  python hpo/submit_experiment.py --stage 2 --model TIMESNET_Q --dataset heat\\n  python hpo/submit_experiment.py --stage 2 --model TIMESNET_Q --dataset water\\n================================================================================\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('STAGE 1 STATUS CHECK')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "check_experiment_status(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcd9a0",
   "metadata": {},
   "source": [
    "## 6. SUBMIT STAGE 2 BY PRIORITY - Select Single Job\n",
    "\n",
    "Submit one Stage 2 quantile calibration experiment by selecting a priority number (1-4).\n",
    "\n",
    "**Prerequisite**: Corresponding Stage 1 job must be complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60c3bd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 2 - SELECT PRIORITY TO SUBMIT\n",
      "================================================================================\n",
      "\n",
      "Available priorities:\n",
      "\n",
      "  1. WATER  + TIMESNET_Q\n",
      "  2. HEAT   + NHITS_Q\n",
      "  3. WATER  + NHITS_Q\n",
      "  4. HEAT   + TIMESNET_Q\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Submitting Stage 2 - Priority 4: HEAT + TIMESNET_Q\n",
      "================================================================================\n",
      "\n",
      "Submitting Stage 2: HEAT + TIMESNET_Q\n",
      "  Script: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/submit_experiment.py\n",
      "  CWD: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "  Command: python /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/submit_experiment.py --stage 2 --model TIMESNET_Q --dataset heat --trials 20\n",
      "  ✓ Submitted as Job 1475599\n",
      "\n",
      "✓ Stage 2 job submitted successfully\n",
      "  Priority: 4\n",
      "  Dataset: HEAT\n",
      "  Model: TIMESNET_Q\n",
      "  Job ID: 1475599\n",
      "  Saved to: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/hpo_current_jobs.json\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('STAGE 2 - SELECT PRIORITY TO SUBMIT')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "print('Available priorities:\\n')\n",
    "for i, (dataset, model) in enumerate(HPO_CONFIG['priority_order'], 1):\n",
    "    print(f'  {i}. {dataset.upper():6} + {model}')\n",
    "\n",
    "print()\n",
    "priority = int(input('Enter priority number (1-4): '))\n",
    "\n",
    "if 1 <= priority <= 4:\n",
    "    dataset, model = HPO_CONFIG['priority_order'][priority - 1]\n",
    "    \n",
    "    print(f'\\n' + '='*80)\n",
    "    print(f'Submitting Stage 2 - Priority {priority}: {dataset.upper()} + {model}')\n",
    "    print('='*80 + '\\n')\n",
    "    \n",
    "    job_id = submit_stage_job(\n",
    "        stage=2,\n",
    "        model=model,\n",
    "        dataset=dataset,\n",
    "        trials=HPO_CONFIG['stage2_trials'],\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    if job_id:\n",
    "        exp_name = f'{dataset}_{model.lower()}_s2'\n",
    "        job_entry = {exp_name: {'job_id': job_id, 'stage': 2, 'status': 'submitted', 'priority': priority}}\n",
    "        \n",
    "        # Save to job map\n",
    "        if os.path.exists(JOB_MAP_FILE):\n",
    "            with open(JOB_MAP_FILE, 'r') as f:\n",
    "                existing = json.load(f)\n",
    "            existing.update(job_entry)\n",
    "        else:\n",
    "            existing = job_entry\n",
    "        \n",
    "        with open(JOB_MAP_FILE, 'w') as f:\n",
    "            json.dump(existing, f, indent=2)\n",
    "        \n",
    "        print(f'\\n✓ Stage 2 job submitted successfully')\n",
    "        print(f'  Priority: {priority}')\n",
    "        print(f'  Dataset: {dataset.upper()}')\n",
    "        print(f'  Model: {model}')\n",
    "        print(f'  Job ID: {job_id}')\n",
    "        print(f'  Saved to: {JOB_MAP_FILE}')\n",
    "    else:\n",
    "        print('✗ Submission failed (Stage 1 may not be complete)')\n",
    "else:\n",
    "    print('Invalid priority number. Please enter 1-4.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472a9419",
   "metadata": {},
   "source": [
    "## 7. SUBMIT STAGE 2 - All Models (Priority Order)\n",
    "\n",
    "After Stage 1 completes, submit all Stage 2 experiments to calibrate quantiles for PICP ≈ 80%.\n",
    "\n",
    "**Prerequisite**: Stage 1 must complete first (automatic check in submit script)\n",
    "**Timeline**: ~2-3 hours per model on A100\n",
    "**Trials**: 20 per model\n",
    "**Output**: calibrated_quantiles.json for each model+dataset combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89598805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SUBMITTING STAGE 2 - QUANTILE CALIBRATION\n",
      "================================================================================\n",
      "\n",
      "Stage 2 will calibrate quantiles for each Stage 1 result\n",
      "Same priority order:\n",
      "\n",
      "  1. WATER  + TIMESNET_Q\n",
      "  2. HEAT   + NHITS_Q\n",
      "  3. WATER  + NHITS_Q\n",
      "  4. HEAT   + TIMESNET_Q\n",
      "\n",
      "Note: Stage 2 automatically checks that Stage 1 completed first.\n",
      "Confirm submission:\n",
      "Submission cancelled.\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('SUBMITTING STAGE 2 - QUANTILE CALIBRATION')\n",
    "print('='*80)\n",
    "print(f'\\nStage 2 will calibrate quantiles for each Stage 1 result')\n",
    "print(f'Same priority order:\\n')\n",
    "\n",
    "for i, (dataset, model) in enumerate(HPO_CONFIG['priority_order'], 1):\n",
    "    print(f'  {i}. {dataset.upper():6} + {model}')\n",
    "\n",
    "print(f'\\nNote: Stage 2 automatically checks that Stage 1 completed first.')\n",
    "print(f'Confirm submission:')\n",
    "response = input('  Submit all Stage 2 jobs? (yes/no): ').strip().lower()\n",
    "\n",
    "if response in ['yes', 'y']:\n",
    "    print('\\n' + '='*80)\n",
    "    stage2_jobs = {}\n",
    "    \n",
    "    for dataset, model in HPO_CONFIG['priority_order']:\n",
    "        job_id = submit_stage_job(\n",
    "            stage=2,\n",
    "            model=model,\n",
    "            dataset=dataset,\n",
    "            trials=HPO_CONFIG['stage2_trials'],\n",
    "            verbose=True\n",
    "        )\n",
    "        if job_id:\n",
    "            exp_name = f'{dataset}_{model.lower()}_s2'\n",
    "            stage2_jobs[exp_name] = {'job_id': job_id, 'stage': 2, 'status': 'submitted'}\n",
    "            print()\n",
    "        else:\n",
    "            print(f'  (Skipping - Stage 1 likely not complete)\\n')\n",
    "    \n",
    "    print('='*80)\n",
    "    print(f'✓ Submitted {len(stage2_jobs)} Stage 2 experiments')\n",
    "    print('='*80)\n",
    "    \n",
    "    # Save job map\n",
    "    if stage2_jobs:\n",
    "        if os.path.exists(JOB_MAP_FILE):\n",
    "            with open(JOB_MAP_FILE, 'r') as f:\n",
    "                existing = json.load(f)\n",
    "            existing.update(stage2_jobs)\n",
    "        else:\n",
    "            existing = stage2_jobs\n",
    "        \n",
    "        with open(JOB_MAP_FILE, 'w') as f:\n",
    "            json.dump(existing, f, indent=2)\n",
    "        print(f'Updated job map: {JOB_MAP_FILE}')\n",
    "else:\n",
    "    print('Submission cancelled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130e7e8",
   "metadata": {},
   "source": [
    "## 8. CHECK STAGE 2 STATUS\n",
    "\n",
    "Monitor Stage 2 experiments as they progress toward PICP calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecb042b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 2 STATUS CHECK\n",
      "================================================================================\n",
      "\n",
      "Checking status (all)...\n",
      "  Script: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis/hpo/check_status.py\n",
      "  CWD: /home/hpc/iwi5/iwi5389h/ExAI-Timeseries-Thesis\n",
      "\n",
      "================================================================================\n",
      "HPO EXPERIMENT STATUS\n",
      "================================================================================\n",
      "\n",
      "STAGE 1: ARCHITECTURE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475012\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:11:34\n",
      "  MAE: 0.002022\n",
      "\n",
      "? HEAT - NHITS_Q\n",
      "  Job ID: 1475013\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:12:41\n",
      "  MAE: 0.026382\n",
      "\n",
      "? WATER - NHITS_Q\n",
      "  Job ID: 1475014\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:13:08\n",
      "  MAE: 0.072588\n",
      "\n",
      "? HEAT - TIMESNET_Q\n",
      "  Job ID: 1475015\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-27 17:13:29\n",
      "  MAE: 0.089717\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475317\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-28 15:32:21\n",
      "  MAE: 0.002022\n",
      "\n",
      "? HEAT - TIMESNET_Q\n",
      "  Job ID: 1475318\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 50\n",
      "  Submitted: 2025-12-28 15:32:30\n",
      "  MAE: 0.089717\n",
      "\n",
      "STAGE 2: CALIBRATION\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475512\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:56:32\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "? HEAT - NHITS_Q\n",
      "  Job ID: 1475513\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:56:57\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "? WATER - NHITS_Q\n",
      "  Job ID: 1475514\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 01:57:05\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "? WATER - TIMESNET_Q\n",
      "  Job ID: 1475598\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 13:07:53\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "? HEAT - TIMESNET_Q\n",
      "  Job ID: 1475599\n",
      "  Status: COMPLETED/FAILED\n",
      "  Trials: 20\n",
      "  Submitted: 2025-12-29 13:08:03\n",
      "  PICP: 0.00% (Target: 80%)\n",
      "  Error: 80.00%\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total experiments: 11\n",
      "Completed: 11\n",
      "Running: 0\n",
      "Pending: 0\n",
      "\n",
      "Stage 1 complete: 4/4\n",
      "  ✓ HEAT - NHITS_Q\n",
      "  ✓ HEAT - TIMESNET_Q\n",
      "  ✓ WATER - NHITS_Q\n",
      "  ✓ WATER - TIMESNET_Q\n",
      "\n",
      "================================================================================\n",
      "NEXT STEPS\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'================================================================================\\nHPO EXPERIMENT STATUS\\n================================================================================\\n\\nSTAGE 1: ARCHITECTURE\\n--------------------------------------------------------------------------------\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475012\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:11:34\\n  MAE: 0.002022\\n\\n? HEAT - NHITS_Q\\n  Job ID: 1475013\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:12:41\\n  MAE: 0.026382\\n\\n? WATER - NHITS_Q\\n  Job ID: 1475014\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:13:08\\n  MAE: 0.072588\\n\\n? HEAT - TIMESNET_Q\\n  Job ID: 1475015\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-27 17:13:29\\n  MAE: 0.089717\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475317\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-28 15:32:21\\n  MAE: 0.002022\\n\\n? HEAT - TIMESNET_Q\\n  Job ID: 1475318\\n  Status: COMPLETED/FAILED\\n  Trials: 50\\n  Submitted: 2025-12-28 15:32:30\\n  MAE: 0.089717\\n\\nSTAGE 2: CALIBRATION\\n--------------------------------------------------------------------------------\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475512\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:56:32\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n? HEAT - NHITS_Q\\n  Job ID: 1475513\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:56:57\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n? WATER - NHITS_Q\\n  Job ID: 1475514\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 01:57:05\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n? WATER - TIMESNET_Q\\n  Job ID: 1475598\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 13:07:53\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n? HEAT - TIMESNET_Q\\n  Job ID: 1475599\\n  Status: COMPLETED/FAILED\\n  Trials: 20\\n  Submitted: 2025-12-29 13:08:03\\n  PICP: 0.00% (Target: 80%)\\n  Error: 80.00%\\n\\n================================================================================\\nSUMMARY\\n================================================================================\\nTotal experiments: 11\\nCompleted: 11\\nRunning: 0\\nPending: 0\\n\\nStage 1 complete: 4/4\\n  ✓ HEAT - NHITS_Q\\n  ✓ HEAT - TIMESNET_Q\\n  ✓ WATER - NHITS_Q\\n  ✓ WATER - TIMESNET_Q\\n\\n================================================================================\\nNEXT STEPS\\n================================================================================\\n================================================================================\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('STAGE 2 STATUS CHECK')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "check_experiment_status(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071211f",
   "metadata": {},
   "source": [
    "## 9. VIEW RESULTS - Stage 1 & Stage 2 Outputs\n",
    "\n",
    "Display and compare optimized hyperparameters and calibrated quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42fc8ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RESULTS - STAGE 1 ARCHITECTURE OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "✓ water_timesnet_q: MAE=0.002022, Trials=50\n",
      "✓ heat_nhits_q: MAE=0.026382, Trials=50\n",
      "✓ water_nhits_q: MAE=0.072588, Trials=53\n",
      "✓ heat_timesnet_q: MAE=0.089717, Trials=51\n",
      "\n",
      "================================================================================\n",
      "Stage 1 Summary:\n",
      "                       MAE  Trials Dataset       Model        LR Dropout\n",
      "water_timesnet_q  0.002022      50   WATER  TIMESNET_Q  0.000538  0.0312\n",
      "heat_nhits_q      0.026382      50    HEAT     NHITS_Q  0.000054  0.0040\n",
      "water_nhits_q     0.072588      53   WATER     NHITS_Q  0.000015  0.4396\n",
      "heat_timesnet_q   0.089717      51    HEAT  TIMESNET_Q  0.003582  0.3182\n",
      "\n",
      "================================================================================\n",
      "RESULTS - STAGE 2 QUANTILE CALIBRATION\n",
      "================================================================================\n",
      "\n",
      "✓ water_timesnet_q: PICP=0.0%, Quantiles=[0.4747, 0.5, 0.5253]\n",
      "✓ heat_nhits_q: PICP=0.0%, Quantiles=[0.3924, 0.5, 0.6076]\n",
      "✓ water_nhits_q: PICP=0.0%, Quantiles=[0.3724, 0.5, 0.6276]\n",
      "✓ heat_timesnet_q: PICP=0.0%, Quantiles=[0.3818, 0.5, 0.6182]\n",
      "\n",
      "================================================================================\n",
      "Stage 2 Summary:\n",
      "                  PICP Target  Error   Q_low  Q_high\n",
      "water_timesnet_q  0.0%    80%  80.0%  0.4747  0.5253\n",
      "heat_nhits_q      0.0%    80%  80.0%  0.3924  0.6076\n",
      "water_nhits_q     0.0%    80%  80.0%  0.3724  0.6276\n",
      "heat_timesnet_q   0.0%    80%  80.0%  0.3818  0.6182\n"
     ]
    }
   ],
   "source": [
    "print('='*80)\n",
    "print('RESULTS - STAGE 1 ARCHITECTURE OPTIMIZATION')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Stage 1 results\n",
    "stage1_results = {}\n",
    "for dataset, model in HPO_CONFIG['priority_order']:\n",
    "    exp_name = f'{dataset}_{model.lower()}'\n",
    "    results_file = f'hpo/results/stage1/{exp_name}/best_params.json'\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        stage1_results[exp_name] = {\n",
    "            'MAE': f\"{data.get('best_mae', 'N/A'):.6f}\",\n",
    "            'Trials': data.get('n_trials', 'N/A'),\n",
    "            'Dataset': dataset.upper(),\n",
    "            'Model': model,\n",
    "            'LR': f\"{data.get('best_params', {}).get('lr', 0):.6f}\",\n",
    "            'Dropout': f\"{data.get('best_params', {}).get('dropout', 0):.4f}\",\n",
    "        }\n",
    "        print(f'✓ {exp_name}: MAE={data.get(\"best_mae\", \"N/A\"):.6f}, Trials={data.get(\"n_trials\", \"N/A\")}')\n",
    "    else:\n",
    "        print(f'  {exp_name}: Not found')\n",
    "\n",
    "if stage1_results:\n",
    "    df1 = pd.DataFrame.from_dict(stage1_results, orient='index')\n",
    "    print('\\n' + '='*80)\n",
    "    print('Stage 1 Summary:')\n",
    "    print(df1.to_string())\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('RESULTS - STAGE 2 QUANTILE CALIBRATION')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "# Stage 2 results\n",
    "stage2_results = {}\n",
    "for dataset, model in HPO_CONFIG['priority_order']:\n",
    "    exp_name = f'{dataset}_{model.lower()}'\n",
    "    results_file = f'hpo/results/stage2/{exp_name}/calibrated_quantiles.json'\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        quantiles = data.get('calibrated_quantiles', [0, 0.5, 0])\n",
    "        stage2_results[exp_name] = {\n",
    "            'PICP': f\"{data.get('achieved_picp', 0):.1f}%\",\n",
    "            'Target': '80%',\n",
    "            'Error': f\"{data.get('calibration_error', 999):.1f}%\",\n",
    "            'Q_low': f\"{quantiles[0]:.4f}\" if len(quantiles) > 0 else 'N/A',\n",
    "            'Q_high': f\"{quantiles[2]:.4f}\" if len(quantiles) > 2 else 'N/A',\n",
    "        }\n",
    "        print(f'✓ {exp_name}: PICP={data.get(\"achieved_picp\", 0):.1f}%, Quantiles=[{quantiles[0]:.4f}, 0.5, {quantiles[2]:.4f}]')\n",
    "    else:\n",
    "        print(f'  {exp_name}: Not found (run Stage 2)')\n",
    "\n",
    "if stage2_results:\n",
    "    df2 = pd.DataFrame.from_dict(stage2_results, orient='index')\n",
    "    print('\\n' + '='*80)\n",
    "    print('Stage 2 Summary:')\n",
    "    print(df2.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c54d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
